{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'important_backlog/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'activities_clusters.pickle'), 'rb') as f:\n",
    "    activities_clusters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'books_clusters.pickle'), 'rb') as f:\n",
    "    books_clusters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# id_book_dict = dict()\n",
    "# for _, books_in_cluster in books_clusters.items():\n",
    "#     for book in books_in_cluster:\n",
    "#         id_book_dict[book['book_id']] = book['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('important_backlog/idbook_booktitle.pickle', 'wb') as f:\n",
    "#     pickle.dump(id_book_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'courses_clusters.pickle'), 'rb') as f:\n",
    "    courses_clusters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'readers_clusters.pickle'), 'rb') as f:\n",
    "    readers_clusters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[163, 164, 165, 168, 170, 171, 173, 174, 176, 177]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(readers_clusters.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'pupils_clusters.pickle'), 'rb') as f:\n",
    "    pupils_clusters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'average_pupils_ratios.pickle'), 'rb') as f:\n",
    "    average_pupils_ratios = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'average_readers_ratios.pickle'), 'rb') as f:\n",
    "    average_readers_ratios = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'last_book_predictor.pickle'), 'rb') as f:\n",
    "    last_book_predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'last_course_predictor.pickle'), 'rb') as f:\n",
    "    last_course_predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'clusters_mapper.pickle'), 'rb') as f:\n",
    "    clusters_mapper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'collaborative_predictor_NOT_FULL.pickle'), 'rb') as f: #to create\n",
    "    collaborative_predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'readers_books_set.pickle'), 'rb') as f: #to create\n",
    "    readers_books_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(readers_clusters.keys())\n",
    "pupils = list(pupils_clusters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip SVD\n",
    "# skip age constraints (needed to be adjusted in databases)\n",
    "def predict(user_id):\n",
    "    if user_id in users:\n",
    "        user_genres = readers_clusters[user_id]['book_ratios']\n",
    "        dominant_cluster = str()\n",
    "        max_ratio = int()\n",
    "        for key, value in user_genres.items():\n",
    "            if value > max_ratio:\n",
    "                max_ratio = value\n",
    "                dominant_cluster = key\n",
    "        user_age = readers_clusters[user_id]['age']\n",
    "        \n",
    "        # top 10 last item\n",
    "        last_item = readers_clusters[user_id]['last_book']\n",
    "        last_item_top_10 = set(last_book_predictor[last_item])\n",
    "        \n",
    "        # top 10 collaborative\n",
    "        the_closest = collaborative_predictor[user_id]\n",
    "        user_set = readers_books_set[user_id]\n",
    "        the_closest_set = readers_books_set[the_closest][0]\n",
    "        collaborative_top_10 = the_closest_set - user_set\n",
    "        \n",
    "        top_5_books = []\n",
    "        both_predict = last_item_top_10 & collaborative_top_10\n",
    "        if both_predict:\n",
    "            top_5_books = list(both_predict)[:5]\n",
    "            \n",
    "        diff = 5 - len(top_5_books)\n",
    "        if diff > 0:\n",
    "            top_5_books = top_5_books + last_item_top_10[:diff]\n",
    "            \n",
    "        # courses\n",
    "        recommended_course = ''\n",
    "        course_cluster, event_cluster = clusters_mapper[dominant_cluster]\n",
    "        if course_cluster:\n",
    "            recommended_course = courses_clusters[course_cluster][0]['title'] # assume storaging popularity sorted\n",
    "            \n",
    "        # events\n",
    "        recommended_event = ''\n",
    "        today = datetime.today()\n",
    "        time_related_events = activities_clusters['time_related']\n",
    "        for time_rel in time_related_events:\n",
    "            delta = (time_rel['event_date'] - today).days\n",
    "            if delta <= 7: #a week before\n",
    "                recommended_event = time_rel['title']\n",
    "                break\n",
    "                \n",
    "        if not recommended_event:\n",
    "            if event_cluster:\n",
    "                recommended_event = activities_clusters[event_cluster][0]['title']\n",
    "                \n",
    "        return top_5_books, recommended_course, recommended_event\n",
    "    \n",
    "    else:\n",
    "        user_courses = pupils_clusters[user_id]['course_ratios']\n",
    "        dominant_cluster = str()\n",
    "        max_ratio = int()\n",
    "        for key, value in user_courses.items():\n",
    "            if value > max_ratio:\n",
    "                max_ratio = value\n",
    "                dominant_cluster = key\n",
    "#         user_age = pupils_clusters[user_id]['age_cat']\n",
    "        \n",
    "        # top 10 last item\n",
    "        last_item = pupils_clusters[user_id]['last_course']\n",
    "        last_item_top_10 = set(last_course_predictor[last_item])\n",
    "        \n",
    "        top_5_courses = last_item_top_10[:5]\n",
    "        \n",
    "        # books\n",
    "        recommended_book = ''\n",
    "        book_cluster, event_cluster = clusters_mapper[dominant_cluster]\n",
    "        if book_cluster:\n",
    "            recommended_book = books_clusters[book_cluster][0]['title'] # assume storaging popularity sorted\n",
    "            \n",
    "        # events\n",
    "        recommended_event = ''\n",
    "        today = datetime.today()\n",
    "        time_related_events = activities_clusters['time_related']\n",
    "        for time_rel in time_related_events:\n",
    "            delta = (time_rel['event_date'] - today).days\n",
    "            if delta <= 7: #a week before\n",
    "                recommended_event = time_rel['title']\n",
    "                break\n",
    "                \n",
    "        if not recommended_event:\n",
    "            if event_cluster:\n",
    "                recommended_event = books_clusters[event_cluster][0]['title']\n",
    "                \n",
    "        return top_5_courses, recommended_book, recommended_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм работы (упрощённая версия)\n",
    "\n",
    "получить на вход id юзера\n",
    "по словарю восстановить профиль юзера - наибольшую ratio кластера (доминирующий кластер) и возраст # другие фичи не берутся в расчёт\n",
    "понять, он ридер или ученик?\n",
    "\n",
    "Если он ридер:\n",
    "    # Предсказываем топ книг\n",
    "    получить топ 10 рекомендаций last_item предиктора\n",
    "    получить топ 10 рекомендаций SVD предиктора\n",
    "    получить топ 10 рекомендаций коллаборативной фильтрации\n",
    "    \n",
    "    создать пустой список топ 5 рекомендаций\n",
    "    попарно найти пересечения всех предикторов\n",
    "    Если пересечения есть:\n",
    "        добавить их в топ 5\n",
    "    \n",
    "    Найти разницу между 5 и длиной топ 5\n",
    "    Если > 0:\n",
    "        добавить в топ 5 разницу из last item\n",
    "    \n",
    "    # кластер не используется для сортировки\n",
    "    \n",
    "    # Предсказываем топ кружков\n",
    "    рекомендуемый кружок = ''\n",
    "    по доминирующему кластеру ищем в мэппинге смежный кластер с кружками\n",
    "    Если кластер есть: # добавить в файл по кластерам кружков фичу о популярности кружка\n",
    "        индекс = 0\n",
    "        До тех пор пока возраст ридера не будет соответствовать возрастным ограничениям кружка:\n",
    "            индекс += 1\n",
    "        получаем кружок для рекомендации\n",
    "    \n",
    "    # Предсказываем топ мероприятий\n",
    "    рекомендуемое мероприятие = ''\n",
    "    получаем текущую дату\n",
    "    для time related мероприятий находим дельту между датой мероприятия и текущей датой\n",
    "    Если дата < 7:\n",
    "        Если возраст соответствует:\n",
    "            получаем мероприятие для рекомендации\n",
    "    \n",
    "    по доминирующему кластеру ищем в мэппинге смежный кластер с мероприятиями\n",
    "    Если кластер есть: # нужна популярность\n",
    "        индекс = 0\n",
    "        До тех пор пока возраст ридера не будет соответствовать возрастным ограничениям мероприятия:\n",
    "            индекс += 1\n",
    "        получаем мероприятие для рекомендации\n",
    "    \n",
    "    возвращаем топ-5, кружок, мероприятие\n",
    "    \n",
    "Если он ученик:\n",
    "    # Предсказываем топ кружков\n",
    "    получить топ 10 рекомендаций last_item предиктора\n",
    "    топ5 для ученика = топ10[:5]\n",
    "    \n",
    "    # Предсказываем топ книг\n",
    "    рекомендуемая книга = ''\n",
    "    по доминирующему кластеру ищем в мэппинге смежный кластер с книгами\n",
    "    Если кластер есть: # добавить в файл по кластерам кружков фичу о популярности книг\n",
    "        берём первую по популярности книгу\n",
    "    \n",
    "    # Предсказываем топ мероприятий\n",
    "    рекомендуемое мероприятие = ''\n",
    "    получаем текущую дату\n",
    "    для time related мероприятий находим дельту между датой мероприятия и текущей датой\n",
    "    Если дата < 7:\n",
    "        Если возраст соответствует:\n",
    "            получаем мероприятие для рекомендации\n",
    "    \n",
    "    по доминирующему кластеру ищем в мэппинге смежный кластер с мероприятиями\n",
    "    Если кластер есть: # нужна популярность\n",
    "        индекс = 0\n",
    "        До тех пор пока возраст ридера не будет соответствовать возрастным ограничениям мероприятия:\n",
    "            индекс += 1\n",
    "        получаем мероприятие для рекомендации\n",
    "    \n",
    "    возвращаем топ-5, кружок, мероприятие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
